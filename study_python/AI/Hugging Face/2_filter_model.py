import torch
from transformers import pipeline
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Use another model and tokenizer in the pipeline åœ¨ç®¡é“ä¸­ä½¿ç”¨å¦ä¸€ä¸ªæ¨¡å‹å’Œæ ‡è®°å™¨
"""
ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨æƒ³è¦ä¸€ä¸ªèƒ½å¤Ÿå¤„ç†æ³•è¯­æ–‡æœ¬çš„æ¨¡å‹ï¼Œè¯·ä½¿ç”¨ Hub ä¸Šçš„æ ‡ç­¾æ¥ç­›é€‰åˆé€‚çš„æ¨¡å‹ã€‚
é¡¶éƒ¨çš„ç­›é€‰ç»“æœè¿”å›ä¸€ä¸ªé’ˆå¯¹æ³•è¯­æ–‡æœ¬çš„æƒ…ç»ªåˆ†æè¿›è¡Œäº†å¾®è°ƒçš„å¤šè¯­è¨€BERT æ¨¡å‹ï¼š
"""
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
# ä½¿ç”¨AutoModelForSequenceClassificationå’Œ
# AutoTokenizeråŠ è½½é¢„è®­ç»ƒæ¨¡å‹åŠå…¶ç›¸å…³çš„æ ‡è®°å™¨
model = AutoModelForSequenceClassification.from_pretrained(model_name)
tokenizer = AutoTokenizer.from_pretrained(model_name)
# åœ¨pipeline()ä¸­æŒ‡å®šæ¨¡å‹å’Œæ ‡è®°å™¨ï¼Œç°åœ¨æ‚¨å¯ä»¥å°†å…¶åº”ç”¨äºclassifieræ³•è¯­æ–‡æœ¬ï¼š

classifier = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)
classifier(
    "Nous sommes trÃ¨s heureux de vous prÃ©senter la bibliothÃ¨que ğŸ¤— Transformers."
)
"""
Device set to use cpu
[{'label': '5 stars', 'score': 0.7272651195526123}]
"""

"""
å¦‚æœæ‚¨æ‰¾ä¸åˆ°é€‚åˆæ‚¨ç”¨ä¾‹çš„æ¨¡å‹ï¼Œåˆ™éœ€è¦å¯¹æ‚¨çš„æ•°æ®è¿›è¡Œé¢„è®­ç»ƒæ¨¡å‹çš„å¾®è°ƒã€‚
æŸ¥çœ‹æˆ‘ä»¬çš„å¾®è°ƒæ•™ç¨‹ä»¥äº†è§£å¦‚ä½•æ“ä½œã€‚
"""
